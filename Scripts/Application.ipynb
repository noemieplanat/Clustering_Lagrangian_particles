{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d0e504e9-5b94-435a-b8fd-d2a83923c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import copy as cp\n",
    "import random\n",
    "import pyproj as proj\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn import cluster\n",
    "import wpca\n",
    "import pandas as pd\n",
    "import pickle \n",
    "from matplotlib.cm import get_cmap\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy as cr\n",
    "import matplotlib.cm as cm\n",
    "from scipy.stats.stats import pearsonr   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "66dd4a5c-a7d6-4ea3-b36a-73bb68d04208",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_SETS = {'all':{'Subset_name':'/storage/nplanat/Glorys12_OP_journalier/NEW_RUN/Sub_samp_y_1993_-_2014_delta_1_100000_start_lon_0.nc',\\\n",
    "                  'init_year':1993,\\\n",
    "                  'final_year':2014,\\\n",
    "                   'delta_year':1,\\\n",
    "                  'N_particles':100000,\\\n",
    "                  'Subset_path':'/storage/nplanat/Glorys12_OP_journalier/NEW_RUN/'},\\\n",
    "           'weird_path_only':{'Subset_name':'/storage/nplanat/Glorys12_OP_journalier/WEIRD/Sub_samp_y_1996_-_1997_-delta_1_40000_start_lon_0.nc',\\\n",
    "                  'init_year':1996,\\\n",
    "                  'final_year':1997,\\\n",
    "                   'delta_year':1,\\\n",
    "                  'N_particles':40000,\\\n",
    "                  'Subset_path':'/storage/nplanat/Glorys12_OP_journalier/WEIRD/'},\\\n",
    "           'without_weird_path':{'Subset_name':None,\\\n",
    "                  'init_year':1993,\\\n",
    "                  'final_year':2014,\\\n",
    "                   'delta_year':1,\\\n",
    "                  'N_particles':100000,\\\n",
    "                  'Subset_path':'/storage/nplanat/Glorys12_OP_journalier/NO_WEIRD/'},\\\n",
    "           'all_short':{'Subset_name':'/storage/nplanat/Glorys12_OP_journalier/SHORT/Sub_samp_y_1993_-_2014_delta_1_100000_start_lon_0.nc',\\\n",
    "                  'init_year':1993,\\\n",
    "                  'final_year':2014,\\\n",
    "                   'delta_year':1,\\\n",
    "                  'N_particles':100000,\\\n",
    "                  'Subset_path':'/storage/nplanat/Glorys12_OP_journalier/SHORT/'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5ba67483-8aa8-4a53-80fb-e0c6cbceb2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_subset = 'all_short'\n",
    "load_previous_run = True\n",
    "init_year = SUB_SETS[sel_subset]['init_year']\n",
    "final_year = SUB_SETS[sel_subset]['final_year']\n",
    "delta_year = SUB_SETS[sel_subset]['delta_year']\n",
    "Subset_name = SUB_SETS[sel_subset]['Subset_name']\n",
    "N_particles = SUB_SETS[sel_subset]['N_particles']\n",
    "Subset_path = SUB_SETS[sel_subset]['Subset_path']\n",
    "\n",
    "files = sorted(glob.glob('/storage/nplanat/Glorys12_OP_journalier/ADV_new_*'))\n",
    "files_m = sorted(glob.glob('/storage/nplanat/Glorys12_OP_journalier/ADV_m_200_*'))\n",
    "files_s = sorted(glob.glob('/storage/nplanat/Glorys12_OP_journalier/ADV_s_200_*'))\n",
    "length_days = 450\n",
    "path_save_prediction = Subset_path \n",
    "\n",
    "\n",
    "perctest = 0.1 \n",
    "perctrain = 0.8\n",
    "trans = True\n",
    "\n",
    "#PCA \n",
    "n_components = 0.9999999\n",
    "\n",
    "# Clustering\n",
    "init = 'k-means++'\n",
    "nmb_initialisations = 20  # number of initiatilisaton for the k-means++ \n",
    "max_iter = 500\n",
    "tol = 5e-4\n",
    "algorithm = 'full'\n",
    "verbose = 0 \n",
    "sample_weight = None\n",
    "n_split = 20  # number of iterations for convergence\n",
    "n_clusters = 20 #number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e016af1b-4fd6-4060-8146-450ae95af5d3",
   "metadata": {},
   "source": [
    "# Load Classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5a5813f6-2bc7-4223-852d-a63abb9ee164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load PCA : \n",
    "with open(Subset_path + 'pca.pkl', 'rb') as pickle_file:\n",
    "    pca = pickle.load(pickle_file)\n",
    "#load clustering : \n",
    "Traj_centroids = np.load(Subset_path+'Traj_centroids.npy', allow_pickle = True)\n",
    "# load previous runs :\n",
    "Labels_valid = np.load(path_save_prediction+'Labels_valid.npy')\n",
    "Labels_test = np.load(path_save_prediction+'Labels_test.npy')\n",
    "lats_test = np.load(path_save_prediction+'lats_test.npy')\n",
    "lons_test = np.load(path_save_prediction+'lons_test.npy')\n",
    "lats_train = np.load(path_save_prediction+'lats_train.npy')\n",
    "lons_train = np.load(path_save_prediction+'lons_train.npy')\n",
    "lats_valid = np.load(path_save_prediction+'lats_valid.npy')\n",
    "lons_valid = np.load(path_save_prediction+'lons_valid.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f81b32-5117-4c8c-9dd9-43eae17e1816",
   "metadata": {},
   "source": [
    "# Apply to all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0ce769a0-c65f-4727-a44f-987446b9796c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_all_per_year(yr, length_days, all_filles) :\n",
    "    file = all_filles[np.where(np.array([int(all_filles[i][-7:-3]) for i in range(len(all_filles))]) == yr)[0][0]]\n",
    "    lats, lons, temps, sal, date, z = extract(file, length_days)    \n",
    "    return lats, lons, temps, sal, date, z\n",
    "\n",
    "def apply_to_all_data(Subset_path, init_year,final_year, length_days, files, t, sp, trans, Traj_centroids):\n",
    "\n",
    "    for yr in range(init_year,final_year):\n",
    "        print('Year', yr)\n",
    "        #lats_all, lons_all, temps_all, sals_all, date_all = extract_all_per_year(yr, length_days, files)\n",
    "        lats_all = np.load('/storage/nplanat/Glorys12_OP_journalier/lats_lons/lats_%i'%yr+'.npy', allow_pickle = True)\n",
    "        lons_all = np.load('/storage/nplanat/Glorys12_OP_journalier/lats_lons/lons_%i'%yr+'.npy', allow_pickle = True)\n",
    "        labels_all = []\n",
    "        for sep in range(0,lats_all.shape[0],sp) :\n",
    "            print(sep,'/',lats_all.shape[0])\n",
    "            lats_all_l = lats_all[sep:sep+sp,:length_days] ; lons_all_l = lons_all[sep:sep+sp,:length_days]\n",
    "            \n",
    "            X_lats_lons_to_classify = Part_1_pre_processing_one_sort(trans, lats_all_l, lons_all_l)\n",
    "            X_reduced_to_classify = pca.transform(X_lats_lons_to_classify)\n",
    "            labels = predict(X_reduced_to_classify, Traj_centroids)\n",
    "            labels_all.extend(labels)\n",
    "        np.save(Subset_path+'labels_data_%i'%yr, labels_all)\n",
    "        #np.save(Subset_path+'/'+'lats_data_%i'%yr, lats_all)\n",
    "        #np.save(Subset_path+'/'+'lons_data_%i'%yr, lons_all)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "39f81df4-6267-43da-b629-4e76d5a880aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T09:36:32.410758Z",
     "start_time": "2022-07-04T09:36:32.406600Z"
    },
    "code_folding": [
     0
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_sets(lats_all, lons_all, temps_all, sals_all, perctest, perctrain):\n",
    "    \n",
    "    s0, s1 = lats_all.shape\n",
    "    data = np.concatenate((lats_all,lons_all), axis=1)\n",
    "    \n",
    "    random.seed(4)\n",
    "    random.shuffle(data)\n",
    "    random.seed(4)\n",
    "    random.shuffle(temps_all)\n",
    "    random.seed(4)\n",
    "    random.shuffle(sals_all)\n",
    "\n",
    "    lats_test = data[:int(perctest*s0), 0:s1]\n",
    "    lons_test = data[:int(perctest*s0), s1:]\n",
    "\n",
    "    lats_train = data[int(perctest*s0):int(perctest*s0)+int(perctrain*s0), 0:s1]\n",
    "    lons_train = data[int(perctest*s0):int(perctest*s0)+int(perctrain*s0), s1:]\n",
    "\n",
    "    lats_valid = data[int(perctest*s0)+int(perctrain*s0):, 0:s1]\n",
    "    lons_valid = data[int(perctest*s0)+int(perctrain*s0):, s1:]\n",
    "\n",
    "    temps_test = temps_all[:int(perctest*s0),:]\n",
    "    sals_test = sals_all[:int(perctest*s0),:]\n",
    "    \n",
    "    temps_train =temps_all[int(perctest*s0):int(perctest*s0)+int(perctrain*s0),:]\n",
    "    sals_train = sals_all[int(perctest*s0):int(perctest*s0)+int(perctrain*s0),:]\n",
    "    \n",
    "    temps_valid = temps_all[int(perctest*s0)+int(perctrain*s0):,:]\n",
    "    sals_valid = sals_all[int(perctest*s0)+int(perctrain*s0):,:]\n",
    "    \n",
    "    return lats_test, lons_test, lats_train, lons_train, lats_valid, lons_valid, temps_train, temps_test, temps_valid, sals_train, sals_test, sals_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0edfc8c6-dd6b-434e-8405-605a0d988310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T09:36:32.421579Z",
     "start_time": "2022-07-04T09:36:32.411647Z"
    },
    "code_folding": [
     0
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lons_in_interval(start_lon, lons):\n",
    "    #this should shift all longitudes so it lies in start_lon + 360. \n",
    "    if start_lon<0 : \n",
    "        print('start_lons should be in [0-360[')\n",
    "        return None\n",
    "    else:\n",
    "        lons_shifted = lons\n",
    "        while np.any(lons_shifted<0):\n",
    "            lons_shifted[lons_shifted<0] = lons_shifted[lons_shifted<0]+360\n",
    "        lons_2 = cp.copy(lons_shifted)\n",
    "        lons_2[lons_shifted>=start_lon] = lons_shifted[lons_shifted>=start_lon] - start_lon\n",
    "        lons_2[lons_shifted<start_lon] = lons_shifted[lons_shifted<start_lon] - start_lon +360\n",
    "        return cp.copy(lons_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3b0e486f-0217-49cd-82cd-98b3f5dead8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T13:16:34.680697Z",
     "start_time": "2022-07-04T13:16:34.677621Z"
    },
    "code_folding": [],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract(path, length_days) :\n",
    "    ds = xr.open_dataset(path)\n",
    "    ds = remove_short(ds)\n",
    "    lats = ds.lat[:,0:length_days].values\n",
    "    lons_i = ds.lon[:,0:length_days].values\n",
    "    lons = lons_in_interval(0, lons_i) # by default start_lon = 360\n",
    "    temps = ds.temperature[:,0:length_days].values\n",
    "    sal = ds.salinity[:,0:length_days].values\n",
    "    z = ds.z[:,0:length_days].values\n",
    "    date = ds.time[:,0].values\n",
    "    return lats, lons, temps, sal, date, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d65fd1df-cc8f-4393-9566-ff6bd40fcc4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T09:36:32.441619Z",
     "start_time": "2022-07-04T09:36:32.432610Z"
    },
    "code_folding": [
     0
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate(lat, lon):\n",
    "    return lat-np.repeat(lat[:,0][:, np.newaxis], lat.shape[1], axis=1), lon-np.repeat(lon[:,0][:, np.newaxis], lon.shape[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "295f6155-7178-47e5-a6ff-966f02aba0c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T09:36:32.452176Z",
     "start_time": "2022-07-04T09:36:32.442617Z"
    },
    "code_folding": [
     0
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Part_1_pre_processing_one_sort(t, la, lo):\n",
    "    if t == True :\n",
    "        lats_train_pp, lons_train_pp = translate(la, lo)\n",
    "\n",
    "    # Reshape\n",
    "    X_lats_lons_train = np.concatenate((lats_train_pp, lons_train_pp), axis = 1) #concatenation of features to make it in the correct shape\n",
    "    X_lats_lons_train[np.isnan(X_lats_lons_train)] = 0 \n",
    "   \n",
    "    return X_lats_lons_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c9a46686-1270-4ae1-8b49-4efe6c130614",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T09:36:32.463071Z",
     "start_time": "2022-07-04T09:36:32.452895Z"
    },
    "code_folding": [],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Part_1_pre_processing(Dataset_path, length_days, perctest, perctrain, t):\n",
    "    lats_all,lons_all, temps_all, sals_all, date_all, depth_all = extract(Dataset_path, length_days)\n",
    "    lats_test, lons_test, lats_train, lons_train, lats_valid, lons_valid, temps_train, temps_test, temps_valid, sals_train, sals_test, sals_valid = split_sets(lats_all, lons_all,temps_all, sals_all, perctest, perctrain)\n",
    "\n",
    "    print('Pre_processing')\n",
    "    # PRE-PROCESSING\n",
    "    X_lats_lons_train = Part_1_pre_processing_one_sort(t, lats_train, lons_train)\n",
    "    X_lats_lons_test = Part_1_pre_processing_one_sort(t, lats_test, lons_test)\n",
    "    X_lats_lons_valid = Part_1_pre_processing_one_sort(t, lats_valid, lons_valid)\n",
    "    \n",
    "    return X_lats_lons_valid, X_lats_lons_test, X_lats_lons_train, lats_test, lons_test, lats_train, lons_train, lats_valid, lons_valid,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2a0a4aca-1fe7-435f-b63a-685c99c005d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(X_reduced_val, X_centers):\n",
    "    \n",
    "    X_reduced_val2 = np.repeat(X_reduced_val[:,:,np.newaxis], X_centers.shape[0], axis = 2)\n",
    "    X_centers2 = np.repeat(np.transpose(X_centers)[np.newaxis,:,:], X_reduced_val.shape[0], axis = 0)\n",
    "    \n",
    "    return np.argmin(np.linalg.norm(X_reduced_val2-X_centers2, axis=1), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "faa62ca2-76b8-4a28-8f77-b1a8672f94d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_to_all_data_m(Subset_path, init_year,final_year, length_days, files, t, sp, trans,Traj_centroids ):\n",
    "\n",
    "    for yr in range(init_year,final_year):\n",
    "        print('Year', yr)\n",
    "        #lats_all, lons_all, temps_all, sals_all, date_all = extract_all_per_year(yr, length_days, files)\n",
    "        lats_all = np.load('/storage/nplanat/Glorys12_OP_journalier/lats_lons/m_lats_%i'%yr+'.npy', allow_pickle = True)\n",
    "        lons_all = np.load('/storage/nplanat/Glorys12_OP_journalier/lats_lons/m_lons_%i'%yr+'.npy', allow_pickle = True)\n",
    "        labels_all = []\n",
    "        for sep in range(0,lats_all.shape[0],sp) :\n",
    "            print(sep,'/',lats_all.shape[0])\n",
    "            lats_all_l = lats_all[sep:sep+sp,:length_days] ; lons_all_l = lons_all[sep:sep+sp,:length_days]\n",
    "            \n",
    "            X_lats_lons_to_classify = Part_1_pre_processing_one_sort(trans, lats_all_l, lons_all_l)\n",
    "            X_reduced_to_classify = pca.transform(X_lats_lons_to_classify)\n",
    "            labels = predict(X_reduced_to_classify, Traj_centroids)\n",
    "            labels_all.extend(labels)\n",
    "        np.save(Subset_path+'m_labels_data_%i'%yr, labels_all)\n",
    "        #np.save(Subset_path+'/'+'lats_data_%i'%yr, lats_all)\n",
    "        #np.save(Subset_path+'/'+'lons_data_%i'%yr, lons_all)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d8883371-8867-42b2-baa6-d2e170341f97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_to_all_data_s(Subset_path, init_year,final_year, length_days, files, t, sp, trans,Traj_centroids ):\n",
    "\n",
    "    for yr in range(init_year,final_year):\n",
    "        print('Year', yr)\n",
    "        #lats_all, lons_all, temps_all, sals_all, date_all = extract_all_per_year(yr, length_days, files)\n",
    "        lats_all = np.load('/storage/nplanat/Glorys12_OP_journalier/lats_lons/s_lats_%i'%yr+'.npy', allow_pickle = True)\n",
    "        lons_all = np.load('/storage/nplanat/Glorys12_OP_journalier/lats_lons/s_lons_%i'%yr+'.npy', allow_pickle = True)\n",
    "        labels_all = []\n",
    "        for sep in range(0,lats_all.shape[0],sp) :\n",
    "            print(sep,'/',lats_all.shape[0])\n",
    "            lats_all_l = lats_all[sep:sep+sp,:length_days] ; lons_all_l = lons_all[sep:sep+sp,:length_days]\n",
    "            \n",
    "            X_lats_lons_to_classify = Part_1_pre_processing_one_sort(trans, lats_all_l, lons_all_l)\n",
    "            X_reduced_to_classify = pca.transform(X_lats_lons_to_classify)\n",
    "            labels = predict(X_reduced_to_classify, Traj_centroids)\n",
    "            labels_all.extend(labels)\n",
    "        np.save(Subset_path+'s_labels_data_%i'%yr, labels_all)\n",
    "        #np.save(Subset_path+'/'+'lats_data_%i'%yr, lats_all)\n",
    "        #np.save(Subset_path+'/'+'lons_data_%i'%yr, lons_all)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bc5424cb-7621-48ad-95e6-a915b6045849",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1993\n",
      "0 / 23129\n",
      "5000 / 23129\n",
      "10000 / 23129\n",
      "15000 / 23129\n",
      "20000 / 23129\n",
      "Year 1994\n",
      "0 / 23154\n",
      "5000 / 23154\n",
      "10000 / 23154\n",
      "15000 / 23154\n",
      "20000 / 23154\n",
      "Year 1995\n",
      "0 / 24140\n",
      "5000 / 24140\n",
      "10000 / 24140\n",
      "15000 / 24140\n",
      "20000 / 24140\n",
      "Year 1996\n",
      "0 / 23589\n",
      "5000 / 23589\n",
      "10000 / 23589\n",
      "15000 / 23589\n",
      "20000 / 23589\n",
      "Year 1997\n",
      "0 / 23424\n",
      "5000 / 23424\n",
      "10000 / 23424\n",
      "15000 / 23424\n",
      "20000 / 23424\n",
      "Year 1998\n",
      "0 / 23578\n",
      "5000 / 23578\n",
      "10000 / 23578\n",
      "15000 / 23578\n",
      "20000 / 23578\n",
      "Year 1999\n",
      "0 / 23619\n",
      "5000 / 23619\n",
      "10000 / 23619\n",
      "15000 / 23619\n",
      "20000 / 23619\n",
      "Year 2000\n",
      "0 / 23119\n",
      "5000 / 23119\n",
      "10000 / 23119\n",
      "15000 / 23119\n",
      "20000 / 23119\n",
      "Year 2001\n",
      "0 / 23331\n",
      "5000 / 23331\n",
      "10000 / 23331\n",
      "15000 / 23331\n",
      "20000 / 23331\n",
      "Year 2002\n",
      "0 / 23207\n",
      "5000 / 23207\n",
      "10000 / 23207\n",
      "15000 / 23207\n",
      "20000 / 23207\n",
      "Year 2003\n",
      "0 / 22522\n",
      "5000 / 22522\n",
      "10000 / 22522\n",
      "15000 / 22522\n",
      "20000 / 22522\n",
      "Year 2004\n",
      "0 / 22509\n",
      "5000 / 22509\n",
      "10000 / 22509\n",
      "15000 / 22509\n",
      "20000 / 22509\n",
      "Year 2005\n",
      "0 / 22593\n",
      "5000 / 22593\n",
      "10000 / 22593\n",
      "15000 / 22593\n",
      "20000 / 22593\n",
      "Year 2006\n",
      "0 / 23610\n",
      "5000 / 23610\n",
      "10000 / 23610\n",
      "15000 / 23610\n",
      "20000 / 23610\n",
      "Year 2007\n",
      "0 / 23754\n",
      "5000 / 23754\n",
      "10000 / 23754\n",
      "15000 / 23754\n",
      "20000 / 23754\n",
      "Year 2008\n",
      "0 / 23604\n",
      "5000 / 23604\n",
      "10000 / 23604\n",
      "15000 / 23604\n",
      "20000 / 23604\n",
      "Year 2009\n",
      "0 / 22623\n",
      "5000 / 22623\n",
      "10000 / 22623\n",
      "15000 / 22623\n",
      "20000 / 22623\n",
      "Year 2010\n",
      "0 / 23120\n",
      "5000 / 23120\n",
      "10000 / 23120\n",
      "15000 / 23120\n",
      "20000 / 23120\n",
      "Year 2011\n",
      "0 / 22796\n",
      "5000 / 22796\n",
      "10000 / 22796\n",
      "15000 / 22796\n",
      "20000 / 22796\n",
      "Year 2012\n",
      "0 / 21923\n",
      "5000 / 21923\n",
      "10000 / 21923\n",
      "15000 / 21923\n",
      "20000 / 21923\n",
      "Year 2013\n",
      "0 / 24098\n",
      "5000 / 24098\n",
      "10000 / 24098\n",
      "15000 / 24098\n",
      "20000 / 24098\n"
     ]
    }
   ],
   "source": [
    "apply_to_all_data(path_save_prediction, 1993,2014, length_days, files, trans, sp = 5000,  trans = trans, Traj_centroids = Traj_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ea4181eb-935a-4f57-b583-586acb7539ed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1993\n",
      "0 / 24562\n",
      "5000 / 24562\n",
      "10000 / 24562\n",
      "15000 / 24562\n",
      "20000 / 24562\n",
      "Year 1994\n",
      "0 / 24339\n",
      "5000 / 24339\n",
      "10000 / 24339\n",
      "15000 / 24339\n",
      "20000 / 24339\n",
      "Year 1995\n",
      "0 / 24475\n",
      "5000 / 24475\n",
      "10000 / 24475\n",
      "15000 / 24475\n",
      "20000 / 24475\n",
      "Year 1996\n",
      "0 / 24456\n",
      "5000 / 24456\n",
      "10000 / 24456\n",
      "15000 / 24456\n",
      "20000 / 24456\n",
      "Year 1997\n",
      "0 / 24417\n",
      "5000 / 24417\n",
      "10000 / 24417\n",
      "15000 / 24417\n",
      "20000 / 24417\n",
      "Year 1998\n",
      "0 / 24467\n",
      "5000 / 24467\n",
      "10000 / 24467\n",
      "15000 / 24467\n",
      "20000 / 24467\n",
      "Year 1999\n",
      "0 / 24496\n",
      "5000 / 24496\n",
      "10000 / 24496\n",
      "15000 / 24496\n",
      "20000 / 24496\n",
      "Year 2000\n",
      "0 / 24485\n",
      "5000 / 24485\n",
      "10000 / 24485\n",
      "15000 / 24485\n",
      "20000 / 24485\n",
      "Year 2001\n",
      "0 / 24489\n",
      "5000 / 24489\n",
      "10000 / 24489\n",
      "15000 / 24489\n",
      "20000 / 24489\n",
      "Year 2002\n",
      "0 / 24189\n",
      "5000 / 24189\n",
      "10000 / 24189\n",
      "15000 / 24189\n",
      "20000 / 24189\n",
      "Year 2003\n",
      "0 / 24112\n",
      "5000 / 24112\n",
      "10000 / 24112\n",
      "15000 / 24112\n",
      "20000 / 24112\n",
      "Year 2004\n",
      "0 / 24503\n",
      "5000 / 24503\n",
      "10000 / 24503\n",
      "15000 / 24503\n",
      "20000 / 24503\n",
      "Year 2005\n",
      "0 / 24436\n",
      "5000 / 24436\n",
      "10000 / 24436\n",
      "15000 / 24436\n",
      "20000 / 24436\n",
      "Year 2006\n",
      "0 / 24525\n",
      "5000 / 24525\n",
      "10000 / 24525\n",
      "15000 / 24525\n",
      "20000 / 24525\n",
      "Year 2007\n",
      "0 / 24413\n",
      "5000 / 24413\n",
      "10000 / 24413\n",
      "15000 / 24413\n",
      "20000 / 24413\n",
      "Year 2008\n",
      "0 / 24440\n",
      "5000 / 24440\n",
      "10000 / 24440\n",
      "15000 / 24440\n",
      "20000 / 24440\n",
      "Year 2009\n",
      "0 / 24397\n",
      "5000 / 24397\n",
      "10000 / 24397\n",
      "15000 / 24397\n",
      "20000 / 24397\n",
      "Year 2010\n",
      "0 / 24590\n",
      "5000 / 24590\n",
      "10000 / 24590\n",
      "15000 / 24590\n",
      "20000 / 24590\n",
      "Year 2011\n",
      "0 / 24469\n",
      "5000 / 24469\n",
      "10000 / 24469\n",
      "15000 / 24469\n",
      "20000 / 24469\n",
      "Year 2012\n",
      "0 / 24108\n",
      "5000 / 24108\n",
      "10000 / 24108\n",
      "15000 / 24108\n",
      "20000 / 24108\n",
      "Year 2013\n",
      "0 / 24471\n",
      "5000 / 24471\n",
      "10000 / 24471\n",
      "15000 / 24471\n",
      "20000 / 24471\n"
     ]
    }
   ],
   "source": [
    "apply_to_all_data_m(path_save_prediction, 1993,2014, length_days, files_m, trans, sp = 5000,  trans = trans, Traj_centroids = Traj_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "384b7dc7-1237-4ed7-88d6-d5f5c75799a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 1993\n",
      "0 / 24657\n",
      "5000 / 24657\n",
      "10000 / 24657\n",
      "15000 / 24657\n",
      "20000 / 24657\n",
      "Year 1994\n",
      "0 / 24597\n",
      "5000 / 24597\n",
      "10000 / 24597\n",
      "15000 / 24597\n",
      "20000 / 24597\n",
      "Year 1995\n",
      "0 / 24576\n",
      "5000 / 24576\n",
      "10000 / 24576\n",
      "15000 / 24576\n",
      "20000 / 24576\n",
      "Year 1996\n",
      "0 / 24491\n",
      "5000 / 24491\n",
      "10000 / 24491\n",
      "15000 / 24491\n",
      "20000 / 24491\n",
      "Year 1997\n",
      "0 / 24503\n",
      "5000 / 24503\n",
      "10000 / 24503\n",
      "15000 / 24503\n",
      "20000 / 24503\n",
      "Year 1998\n",
      "0 / 24577\n",
      "5000 / 24577\n",
      "10000 / 24577\n",
      "15000 / 24577\n",
      "20000 / 24577\n",
      "Year 1999\n",
      "0 / 24583\n",
      "5000 / 24583\n",
      "10000 / 24583\n",
      "15000 / 24583\n",
      "20000 / 24583\n",
      "Year 2000\n",
      "0 / 24620\n",
      "5000 / 24620\n",
      "10000 / 24620\n",
      "15000 / 24620\n",
      "20000 / 24620\n",
      "Year 2001\n",
      "0 / 24641\n",
      "5000 / 24641\n",
      "10000 / 24641\n",
      "15000 / 24641\n",
      "20000 / 24641\n",
      "Year 2002\n",
      "0 / 24587\n",
      "5000 / 24587\n",
      "10000 / 24587\n",
      "15000 / 24587\n",
      "20000 / 24587\n",
      "Year 2003\n",
      "0 / 24475\n",
      "5000 / 24475\n",
      "10000 / 24475\n",
      "15000 / 24475\n",
      "20000 / 24475\n",
      "Year 2004\n",
      "0 / 24569\n",
      "5000 / 24569\n",
      "10000 / 24569\n",
      "15000 / 24569\n",
      "20000 / 24569\n",
      "Year 2005\n",
      "0 / 24631\n",
      "5000 / 24631\n",
      "10000 / 24631\n",
      "15000 / 24631\n",
      "20000 / 24631\n",
      "Year 2006\n",
      "0 / 24563\n",
      "5000 / 24563\n",
      "10000 / 24563\n",
      "15000 / 24563\n",
      "20000 / 24563\n",
      "Year 2007\n",
      "0 / 24589\n",
      "5000 / 24589\n",
      "10000 / 24589\n",
      "15000 / 24589\n",
      "20000 / 24589\n",
      "Year 2008\n",
      "0 / 24624\n",
      "5000 / 24624\n",
      "10000 / 24624\n",
      "15000 / 24624\n",
      "20000 / 24624\n",
      "Year 2009\n",
      "0 / 24621\n",
      "5000 / 24621\n",
      "10000 / 24621\n",
      "15000 / 24621\n",
      "20000 / 24621\n",
      "Year 2010\n",
      "0 / 24630\n",
      "5000 / 24630\n",
      "10000 / 24630\n",
      "15000 / 24630\n",
      "20000 / 24630\n",
      "Year 2011\n",
      "0 / 23869\n",
      "5000 / 23869\n",
      "10000 / 23869\n",
      "15000 / 23869\n",
      "20000 / 23869\n",
      "Year 2012\n",
      "0 / 21600\n",
      "5000 / 21600\n",
      "10000 / 21600\n",
      "15000 / 21600\n",
      "20000 / 21600\n",
      "Year 2013\n",
      "0 / 24568\n",
      "5000 / 24568\n",
      "10000 / 24568\n",
      "15000 / 24568\n",
      "20000 / 24568\n"
     ]
    }
   ],
   "source": [
    "apply_to_all_data_s(path_save_prediction, 1993, 2014, length_days, files_s, trans, sp = 5000,  trans = trans, Traj_centroids = Traj_centroids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(analysis)",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
